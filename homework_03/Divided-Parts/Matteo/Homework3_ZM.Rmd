---
title: "Hoomework 3"
author: "Group B"
date: "7/5/2020"
output: html_document
---


# Homework 3 {.tabset}

## LAB Exercises {.tabset}

### Exercise 1

So far, we used **R** simply as a pocket calculator, computing MLE and the variance of our estimators analitically, and then obtaining the numerical values just plugging into the formulas the inputs. However, remind the MLE for $\gamma$, where the equation

\begin{equation*} \frac{n}{\gamma} + \sum_{i=1}^n \log(y_i) - n \frac{\sum_i y_i^{\gamma}\log(y_i)}{\sum_i y_i^{\gamma}} = 0 \end{equation*}

does not have an analytical solution. Many times we do not have a closed form for MLE estimates and we may need **numerical optimization**. **R** provides various functions for performing numerical methods, of which we will see two in particular:

- **nlm()**: minimizes a function using a Newton-type algorithm. It needs a starting value and does not allow constraints on the parameters. It is usually fast and reliable. It returns the ML estimate $\hat{\theta}$ (**estimate**), the value of the likelihood $−l(\hat{\theta})$ (**minimum**) and the hessian (**hessian**), if **hessian = TRUE**.

- **optim()**: minimizes a function using Nelder-Mead, quasi-Newton and conjugate gradients algorithms. It includes an option for box-constrained optimization, and it requires a starting value. It returns the ML estimate $\hat{\theta}$ (**par**) and the value of the likelihood $−l(\hat{\theta})$ (**value**).

```{r Ex 1.0, message = FALSE, warning = FALSE}
y <- c(155.9, 200.2, 143.8, 150.1,152.1, 142.2, 147, 146, 146,
       170.3, 148, 140, 118, 144, 97)
n <- length(y)

# log-likelihood function
log_lik_weibull <- function(data, param){
  -sum(dweibull(data, shape = param[1], scale = param[2], log = TRUE))
}

 #define parameters grid
 gamma <- seq(0.1, 15, length=100)
 beta <- seq(100,200, length=100)
 
 parvalues <- expand.grid(gamma,beta)
 llikvalues <- apply(parvalues, 1, log_lik_weibull, data=y)
 llikvalues <- matrix(-llikvalues, nrow = length(gamma), ncol=length(beta),
                      byrow=F)
 conf.levels <- c(0, 0.5, 0.75, 0.9, 0.95, 0.99)
 
 #contour plot
 contour(gamma, beta, llikvalues - max(llikvalues),
         levels = -qchisq(conf.levels, 2)/2,
         xlab = expression(gamma),
         labels = as.character(conf.levels),
         ylab = expression(beta))
 title('Weibull relative log likelihood')
 
  #image
 image(gamma, beta, llikvalues - max(llikvalues), zlim = c(-6,0),
       col = terrain.colors(20),
       xlab = expression(gamma),
       ylab = expression(beta))
 title('Weibull relative log likelihood')


gammahat <- uniroot(function(x) n/x+sum(log(y))-n*sum(y^x*log(y))/sum(y^x), c(1e-5,15))$root
betahat <- mean(y^gammahat)^(1/gammahat)
weib.y.mle <- c(gammahat,betahat)

#observed information matrix
jhat <- matrix(NA, nrow=2, ncol=2)
jhat[1,1] <- n/gammahat^2 + sum((y/betahat)^gammahat*(log(y/betahat))^2)
jhat[1,2] <- jhat[2,1] <- n/betahat - sum(y^gammahat/betahat^(gammahat+1)*(gammahat*log(y/betahat) + 1))
jhat[2,2] <- -n*gammahat/betahat^2 + gammahat*(gammahat + 1)/
betahat^(gammahat + 2)*sum(y^gammahat)
solve(jhat)

#se of the mle
mle.se<-sqrt(diag(solve(jhat)))
mle.se

#first element is the MLE for the shape gamma, second element the MLE for the scale beta
weib.y.mle

weib.y.nlm <- nlm(log_lik_weibull, c(0,0), hessian = T, data = y)
weib.y.nlm

omega <- function(theta) log(theta)
theta <- function(omega) exp(omega)

log_lik_weibull_rep <- function(data, param) log_lik_weibull(data, theta(param))
weib.y.nlm <- nlm(log_lik_weibull_rep,c(0,0),hessian=T,data=y)
weib.y.nlm

theta(weib.y.nlm$estimate)

weib.y.mle
```

The **optim()** function provides a lot of numerical methods, such us Nelder-Mead, quasi-Newton, conjugate-gradient methods and simulated annealings. As a drawback, the user has to set up very carefully the initial parameters and the adopted method, since the final solution may be quite sensitive to these choices. To compute the observed information, the function **optimHess()** computes numerical derivatives of generic functions.

```{r Ex 1.0.1, message = FALSE, warning = FALSE}
# gamma = 1, beta = 20 as initial choices with quasi-Newton method
weib.y.optim.qn <- optim(c(1,20), log_lik_weibull_rep, NULL, method =  "BFGS", data=y)
weib.y.optim.qn
theta(weib.y.optim.qn$par)

# gamma = 1, beta = 6 as initial choices with conjugate-gradient method.
weib.y.optim.cg <- optim(c(1,6), log_lik_weibull_rep, NULL, method =  "CG", data=y)$par
theta(weib.y.optim.cg)

optimHess(theta(weib.y.nlm$estimate),log_lik_weibull,data=y)

jhat
```

Use **nlm()** to compute the variance for the estimator $\hat{\omega} =(\log(\hat{\gamma}), \log(\hat{\beta}))$ and **optimHess()** for the variance of $\hat{\theta} = (\hat{\gamma}, \hat{\beta})$.

#### Solution

```{r Ex 1.1, message = FALSE, warning = FALSE}
#thetahat <- c(gammahat, betahat)


# Variance of the omegahat estimator
# reparametrization of the parameter in the log likelihood
log_lik_weibull_omega <- function(data, param) log_lik_weibull(data, omega(param))

omega_nlm <- nlm(log_lik_weibull_omega, c(1000, 4e67), hessian = T, data = y)
omega_nlm
omega(omega_nlm$estimate)

var_omega <- diag(solve(omega_nlm$hessian))
var_omega


# Variance of the thetahat estimator 
opt_theta <- optim(c(1, 5), log_lik_weibull, hessian = T, data = y)
opt_theta

var_theta <- diag(solve(opt_theta$hessian))
var_theta


#-------------------------------------------------
#variance <- function(data, param, parametrization) {
#  if(parametrization == "omega") {
#    a <- nlm(log_lik_weibull_rep_omega, param, hessian = T, data = y)
#    weib_var <- a$estimate[1]*factorial(1+1/a$estimate[2])
#    return(2*weib_var^2/length(data))
#  }
#  else if(parametrization == "theta") {
#    a <- optim(param, fn = log_lik_weibull_rep, NULL, method = "CG", data = y)
#    weib_var <- a$par[1]*(1+1/a$par[2])
#    return(2*weib_var^2/length(data))
#  }
#}

#min_var_omega <- nlm(variance, c(21, 123), hessian = T, data = y, parametrization = "omega")
#min_var_omega$minimum

#min_var_theta <- optim(c(2, 10), variance, NULL, method = "BFGS", data = y, parametrization = "theta")
#min_var_theta$value

#optimHess(b$par, log_lik_weibull_rep_omega, data = y)


```













### Exercise 2

In practical situations, some components of the parameter vector $\theta$ are more important than others; essentially, in such situations it is of interest for us making inference only on those subgroups of parameters. In the Weibull case, we could treat $\gamma$ as the *parameter of interest* and $\beta$ as the *nuisance* parameter. We may then define the **profile log-likelihood**:

\begin{equation*} l_P(\gamma) = \max_{\beta} l(\gamma, \beta; y) = l(\gamma, \hat{\beta}_{\gamma}; y), \end{equation*}

where $\hat{\beta}_{\gamma}$ is the *constrained* MLE for $\beta$, with $\gamma$ fixed. Some issues deserve a quick consideration:

- the profile log-likelihood is simply the log-likelihood for the bidimensional parameter $\theta$, with the nuisance component $\beta$ replaced by
\begin{equation*} \hat{\beta}_{\gamma} = \big( \sum_{i=1}^n y_i^{\gamma}/n\big)^{1/\gamma}. \end{equation*}

- $l_P$ is not a *genuine* likelihood. However, it has some nice features  which ease to work with. 

```{r Ex 2.0, message = FALSE, warning = FALSE}

weib.y.mle <- optim(c(1, 1), log_lik_weibull, NULL, hessian = T, method = 'BFGS', 
                    lower = rep(1e-7, 2), upper = rep(Inf, 2), data = y)

gamma <- seq(0.1, 15, length = 100)
beta <- seq(100, 200, length = 100)
parvalues <- expand.grid(gamma, beta)

llikvalues <- apply(parvalues, 1, log_lik_weibull, data = y)
llikvalues <- matrix(-llikvalues, nrow=length(gamma), ncol = length(beta), byrow = F)

conf.levels <- c(0, 0.5, 0.75, 0.9, 0.95, 0.99)

#contour plot
contour(gamma, beta, llikvalues - max(llikvalues),
       levels = -qchisq(conf.levels, 2)/2,
       xlab = expression(gamma),
       labels = as.character(conf.levels),
       ylab = expression(beta))
title('Weibull profile log-likelihood')

beta.gamma <- sapply(gamma, function(x) mean(y^x)^(1/x))
lines(gamma, beta.gamma, lty = 'dashed', col = 2)
points(weib.y.mle$par[1], weib.y.mle$par[2])
```

In some sense, we *reduced the dimension* of the problem, and we acknowledged that we may work with a one-dimensional likelihood evaluated in the constrained value $\hat{\beta}_{\gamma}$ for the nuisance component. Then, we may now compute some **deviance confidence intervals** with level $1-\alpha$ as:

\begin{equation*} \{\gamma \colon l_P(\gamma) \geq l_P (\hat{\gamma}) - \frac{1}{2} \chi^2_{1;\-\alpha} \} \end{equation*}

where $\chi^2_{1;1-\alpha}$ is the $1-\alpha$-th quantile of a chi-squared distribution with $1$ degree of freedom, the asymptotic distribution for the **profile likelihood-ratio test statistic**:

\begin{equation*} W_P(\gamma) = 2\{l_P(\hat{\gamma})-l_P(\gamma)\}. \end{equation*}

```{r Ex 2.0.1, warning = FALSE, message = FALSE}

log_lik_weibull_profile  <- function(data, gamma){
  beta.gamma <- mean(data^gamma)^(1/gamma)
 log_lik_weibull( data, c(gamma, beta.gamma) )
}

log_lik_weibull_profile_v <- Vectorize(log_lik_weibull_profile, 'gamma'  )

plot(function(x) -log_lik_weibull_profile_v(data = y, x) + weib.y.mle$value, 
     from = 0.1, to = 15,
     xlab = expression(gamma),
     ylab = 'profile relative log likelihood',
     ylim = c(-8,0))

conf.level <- 0.95
abline(h = -qchisq(conf.level,1)/2, lty = 'dashed', col = 2)



lrt.ci1 <- uniroot(function(x) -log_lik_weibull_profile_v(y, x) + weib.y.mle$value + qchisq(conf.level,1)/2,
                 c(1e-7, weib.y.mle$par[1]))$root

lrt.ci1 <- c(lrt.ci1, uniroot(function(x) -log_lik_weibull_profile_v(y,x) + weib.y.mle$value + qchisq(conf.level,1)/2,
                              c(weib.y.mle$par[1], 15))$root)

segments(lrt.ci1[1],-qchisq(conf.level,1)/2, lrt.ci1[1],
        -log_lik_weibull_profile_v(y, lrt.ci1[1]), col="red", lty = 2)

segments(lrt.ci1[2],-qchisq(conf.level,1)/2, lrt.ci1[2],
         -log_lik_weibull_profile_v(y, lrt.ci1[2]), col="red", lty = 2)

points(lrt.ci1[1], -qchisq(0.95,1)/2, pch = 16, col = 2, cex = 1.5)
points(lrt.ci1[2], -qchisq(0.95,1)/2, pch = 16, col = 2, cex = 1.5)

segments( lrt.ci1[1], -8.1, 
          lrt.ci1[2], 
          -8.1, col="red", lty = 1, lwd = 2)

text(7, -7.5, "95% Deviance CI", col = 2)
```

The **Wald confidence interval** with level $1 - \alpha$ is defined as:

\begin{equation*} \hat{\gamma} \pm z_{1-\alpha/2}j_P(\hat{\gamma})^{-1/2}. \end{equation*}

Compute the Wald confidence interval of level $0.95$ and plot the result.

#### Solution

```{r Ex 2.1, warning = FALSE, message = FALSE}

#  Incorrect variance
#wald_level3 <- 1.96*sqrt(var(dweibull(y, weib.y.mle$par[1], weib.y.mle$par[2])))
#wald_level3

# Same as before, but using the actual formula in place of the function
#wald_level2 <- 1.96*sqrt(weib.y.mle$par[1]^2*(gamma(1+2/weib.y.mle$par[2])-(gamma(1+1/weib.y.mle$par[2])^2)))
#wald_level2

# The one I choose using the value of var(gamma), that I took from LAB2, ex 4
wald_level <- 1.96*sqrt(mle.se[1])
wald_level



plot(function(x) -log_lik_weibull_profile_v(data=y, x) + weib.y.mle$value, 
     from = 0.1, to = 15,
     xlab = expression(gamma),
     ylab = 'profile relative log likelihood',
     ylim = c(-8,0))


lrt.ci1 <- c(uniroot(function(x) -log_lik_weibull_profile_v(y, x) + weib.y.mle$value + wald_level, c(1e-7, weib.y.mle$par[1]))$root,
             uniroot(function(x) -log_lik_weibull_profile_v(y, x) + weib.y.mle$value + wald_level, c(weib.y.mle$par[1], 15))$root)


abline(h = -log_lik_weibull_profile_v(y, lrt.ci1[1]) + weib.y.mle$value,lty = 'dashed', col=2)

segments(lrt.ci1[1],-log_lik_weibull_profile_v(y, lrt.ci1[1]) + weib.y.mle$value, 
         lrt.ci1[1], -log_lik_weibull_profile_v(y, lrt.ci1[1]), 
         col="red", lty = 2)

segments(lrt.ci1[2], -log_lik_weibull_profile_v(y, lrt.ci1[2]) + weib.y.mle$value, 
         lrt.ci1[2], -log_lik_weibull_profile_v(y, lrt.ci1[2]), 
         col="red", lty = 2)

points(lrt.ci1[1], -log_lik_weibull_profile_v(y, lrt.ci1[1]) + weib.y.mle$value, pch = 16, col = 2, cex = 1.5)
points(lrt.ci1[2], -log_lik_weibull_profile_v(y, lrt.ci1[2]) + weib.y.mle$value, pch = 16, col = 2, cex = 1.5)

segments(lrt.ci1[1], -8.1, 
         lrt.ci1[2], -8.1,
         col="red", lty = 1, lwd = 2)

text(7, -7.5, "95% Wald CI", col = 2)
```















### Exercise 3

Repeat the steps of the previous exercise —write the profile log-likelihood, plot it and find the deviance confidence intervals— considering this time $\gamma$ as a *nuisance parameter* and $\beta$ as the *parameter of interest*.

#### Solution

We need to find the profile log likelihood:

\begin{equation*} l_P(\beta) = \max_{\gamma} l(\beta, \gamma; y) = l(\beta, \hat{\gamma}_{\beta}; y), \end{equation*}

where this time $\hat{\gamma}_{\beta}$ is the constrained MLE for $\gamma$, with $\beta$ fixed:

\begin{equation*} \hat{\gamma}_{\beta} = \big( \sum_{i=1}^n y_i^{\beta}/n\big)^{1/\beta}. \end{equation*}

\begin{equation*} \frac{n}{\gamma} - n\log(\beta) + \sum_{i=1}^n\log(y_i) - \sum_{i=1}^n \Big(\frac{y_i}{\beta}\Big)^{\gamma}\log\Big(\frac{y_i}{\beta}\Big) = 0 \end{equation*}

\begin{align*} \frac{n}{\gamma} - \sum_{i=1}^n \Big(\frac{y_i}{\beta}\Big)^{\gamma}\log\Big(\frac{y_i}{\beta}\Big) &= n\log(\beta) - \sum_{i=1}^n \log(y_i) \\ \sum_{i=1}^n \Big(\frac{1}{\gamma} - \Big(\frac{y_i}{\beta}\Big)^{\gamma}\log\Big(\frac{y_i}{\beta}\Big)\Big) &= n\log(\beta) - \sum_{i=1}^n \log(y_i) \\
\end{align}


```{r Ex 3.1, message = FALSE, warning = FALSE}



gamma <- seq(0.1, 15, length = 100)
beta <- seq(100, 200, length = 100)
parvalues <- expand.grid(gamma, beta)


llikvalues <- apply(parvalues, 1, log_lik_weibull, data = y)
llikvalues <- matrix(-llikvalues, nrow=length(gamma), ncol = length(beta), byrow = F)
x <- seq(0,100, length = 1000)

conf.levels <- c(0, 0.5, 0.75, 0.9, 0.95, 0.99)

#contour plot
contour(gamma, beta,  llikvalues - max(llikvalues),
       levels = -qchisq(conf.levels, 2)/2,
       xlab = expression(beta),
       labels = as.character(conf.levels),
       ylab = expression(gamma))
title('Weibull profile log-likelihood')

beta.gamma <- sapply(gamma, function(x) mean(y^x)^(1/x))
lines(gamma, beta.gamma, lty = 'dashed', col = 2)
points(weib.y.mle$par[1], weib.y.mle$par[1])

log_lik_weibull_profile  <- function(data, gamma){
  beta.gamma <- mean(data^gamma)^(1/gamma)
 log_lik_weibull( data, c(gamma, beta.gamma) )
}

log_lik_weibull_profile_v <- Vectorize(log_lik_weibull_profile, 'gamma'  )


plot(function(x) -log_lik_weibull_profile_v(data = y, x) + weib.y.mle$value, 
     from = 0.1, to = 15,
     xlab = expression(gamma),
     ylab = 'profile relative log likelihood',
     ylim = c(-8,0))

conf.level <- 0.95
abline(h = -qchisq(conf.level,1)/2, lty = 'dashed', col = 2)


lrt.ci1 <- uniroot(function(x) -log_lik_weibull_profile_v(y, x) + weib.y.mle$value + qchisq(conf.level,1)/2,
                 c(1e-7, weib.y.mle$par[1]))$root

lrt.ci1 <- c(lrt.ci1, uniroot(function(x) -log_lik_weibull_profile_v(y,x) + weib.y.mle$value + qchisq(conf.level,1)/2,
                              c(weib.y.mle$par[1], 15))$root)

segments(lrt.ci1[1],-qchisq(conf.level,1)/2, lrt.ci1[1],
        -log_lik_weibull_profile_v(y, lrt.ci1[1]), col="red", lty = 2)

segments(lrt.ci1[2],-qchisq(conf.level,1)/2, lrt.ci1[2],
         -log_lik_weibull_profile_v(y, lrt.ci1[2]), col="red", lty = 2)

points(lrt.ci1[1], -qchisq(0.95,1)/2, pch = 16, col = 2, cex = 1.5)
points(lrt.ci1[2], -qchisq(0.95,1)/2, pch = 16, col = 2, cex = 1.5)

segments( lrt.ci1[1], -8.1, 
          lrt.ci1[2], 
          -8.1, col="red", lty = 1, lwd = 2)

text(7, -7.5, "95% Deviance CI", col = 2)
```
